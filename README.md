# Console-Chat-for-Meta-Llama-Inst

–≠—Ç–æ –∫–æ–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GPT –º–æ–¥–µ–ª—å—é Meta-Llama-B-Instruct –≤ –∫–æ–Ω—Å–æ–ª–µ.

–î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –∫–æ–¥–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å –ø–æ —ç—Ç–æ–π —Å—Å—ã–ª–∫–µ: `https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct`

–≠—Ç–æ—Ç –∫–æ–¥ —Å–æ–∑–¥–∞–Ω –≤ —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª—è—Ö –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è.  
–í—ã –º–æ–∂–µ—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ, –∏–∑–º–µ–Ω—è—Ç—å, –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –∏ –∏–¥–µ–∏.
> ü§ç –ï—Å–ª–∏ –∫–æ–¥ –æ–∫–∞–∑–∞–ª—Å—è –ø–æ–ª–µ–∑–µ–Ω ‚Äî –¥–∞–π—Ç–µ –∑–Ω–∞—Ç—å. –≠—Ç–æ –º–æ—Ç–∏–≤–∏—Ä—É–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å –¥–∞–ª—å—à–µ!

–•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ RTX 2060 Super (8 –ì–ë VRAM)

## –ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—Å—è —ç—Ç–∏–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º:

‚ö† Python –≤–µ—Ä—Å–∏—è 3.9+

C–∫–∞—á–∞–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–¥–æ–±–Ω—ã–º –≤–∞–º —Å–ø–æ—Å–æ–±–æ–º –≤ –ö–æ–Ω—Å–æ–ª–∏ –∏–ª–∏ PowerShell:
`git clone https://github.com/KD2D/Chat-for-Meta-Llama-Inst.git`

–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA 12.1:
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
`pip install -r requirements.txt`

–ó–∞–ø—É—Å—Ç–∏—Ç–µ `Up_Model.py`

–ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –ø–æ–ª—É—á–∏—Ç –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å, —è –ø–µ—Ä–µ–≤–µ–¥—É –≤—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–¥–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫–∏.
<br><br>

---

This is the code for working with the Meta-Llama-B-Instruct GPT model in the console.

To ensure proper operation of the code, make sure to install the model from this link: `https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct`

This code was created for educational purposes and is under active development.  
You are free to use it, modify it, and suggest improvements and ideas.  
> ü§ç If the code was useful ‚Äî let me know. That motivates further development!

Works well on RTX 2060 Super (8 GB VRAM)

## How to use this repository:

‚ö† Python version 3.9+

Download the repository in any convenient way using Console or PowerShell:
`git clone https://github.com/KD2D/Chat-for-Meta-Llama-Inst.git`

Install PyTorch with CUDA 12.1:
`pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`

Install the remaining dependencies:
`pip install -r requirements.txt`

Run `Up_Model.py`

If the project becomes popular, I will translate all comments in the code into both Russian and English.
